{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ek_uglWWVEBB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "633e261f-1a49-42c9-aeb8-c44642943604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 Loss: 1.8161826133728027 Avg Accuracy: 0.359375\n",
            "Epoch: 2 Loss: 1.1336917877197266 Avg Accuracy: 0.3645833333333333\n",
            "Epoch: 3 Loss: 0.6326448321342468 Avg Accuracy: 0.5364583333333334\n",
            "Epoch: 4 Loss: 0.9056510925292969 Avg Accuracy: 0.65625\n",
            "Epoch: 5 Loss: 0.8486098647117615 Avg Accuracy: 0.6145833333333334\n",
            "Epoch: 6 Loss: 0.6760177612304688 Avg Accuracy: 0.6614583333333334\n",
            "Epoch: 7 Loss: 0.48215997219085693 Avg Accuracy: 0.703125\n",
            "Epoch: 8 Loss: 0.7024503946304321 Avg Accuracy: 0.6927083333333334\n",
            "Epoch: 9 Loss: 0.7251882553100586 Avg Accuracy: 0.6875\n",
            "Epoch: 10 Loss: 0.7142814993858337 Avg Accuracy: 0.796875\n",
            "Epoch: 11 Loss: 0.47937220335006714 Avg Accuracy: 0.765625\n",
            "Epoch: 12 Loss: 0.12516744434833527 Avg Accuracy: 0.7552083333333334\n",
            "Epoch: 13 Loss: 1.6527082920074463 Avg Accuracy: 0.734375\n",
            "Epoch: 14 Loss: 1.092834711074829 Avg Accuracy: 0.6302083333333334\n",
            "Epoch: 15 Loss: 0.3312925696372986 Avg Accuracy: 0.8125\n",
            "Epoch: 16 Loss: 0.5108392834663391 Avg Accuracy: 0.7708333333333334\n",
            "Epoch: 17 Loss: 0.44117385149002075 Avg Accuracy: 0.8489583333333334\n",
            "Epoch: 18 Loss: 0.4540400803089142 Avg Accuracy: 0.8229166666666666\n",
            "Epoch: 19 Loss: 0.0025127858389168978 Avg Accuracy: 0.8489583333333334\n",
            "Epoch: 20 Loss: 0.4718831777572632 Avg Accuracy: 0.8541666666666666\n",
            "Epoch: 21 Loss: 0.04116556793451309 Avg Accuracy: 0.9322916666666666\n",
            "Epoch: 22 Loss: 0.20560641586780548 Avg Accuracy: 0.9010416666666666\n",
            "Epoch: 23 Loss: 0.0016627076547592878 Avg Accuracy: 0.8958333333333334\n",
            "Epoch: 24 Loss: 0.31520789861679077 Avg Accuracy: 0.890625\n",
            "Epoch: 25 Loss: 0.04097948595881462 Avg Accuracy: 0.890625\n",
            "Epoch: 26 Loss: 0.05489424243569374 Avg Accuracy: 0.8958333333333334\n",
            "Epoch: 27 Loss: 0.48438021540641785 Avg Accuracy: 0.9427083333333334\n",
            "Epoch: 28 Loss: 0.3025968670845032 Avg Accuracy: 0.9114583333333334\n",
            "Epoch: 29 Loss: 0.9842509627342224 Avg Accuracy: 0.8854166666666666\n",
            "Epoch: 30 Loss: 0.0185526255518198 Avg Accuracy: 0.921875\n",
            "Epoch: 31 Loss: 0.040977682918310165 Avg Accuracy: 0.875\n",
            "Epoch: 32 Loss: 0.41749656200408936 Avg Accuracy: 0.8854166666666666\n",
            "Epoch: 33 Loss: 1.3297922611236572 Avg Accuracy: 0.875\n",
            "Epoch: 34 Loss: 0.005161386914551258 Avg Accuracy: 0.9010416666666666\n",
            "Epoch: 35 Loss: 0.38282302021980286 Avg Accuracy: 0.9427083333333334\n",
            "Epoch: 36 Loss: 0.828851580619812 Avg Accuracy: 0.9010416666666666\n",
            "Epoch: 37 Loss: 0.0978335291147232 Avg Accuracy: 0.9166666666666666\n",
            "Epoch: 38 Loss: 0.00814538262784481 Avg Accuracy: 0.9322916666666666\n",
            "Epoch: 39 Loss: 0.005255991127341986 Avg Accuracy: 0.9479166666666666\n",
            "Epoch: 40 Loss: 0.00887971930205822 Avg Accuracy: 0.9427083333333334\n",
            "Epoch: 41 Loss: 0.11906760185956955 Avg Accuracy: 0.9427083333333334\n",
            "Epoch: 42 Loss: 0.46187645196914673 Avg Accuracy: 0.9166666666666666\n",
            "Epoch: 43 Loss: 0.005645911209285259 Avg Accuracy: 0.9322916666666666\n",
            "Epoch: 44 Loss: 0.20818263292312622 Avg Accuracy: 0.9114583333333334\n",
            "Epoch: 45 Loss: 0.01423699501901865 Avg Accuracy: 0.9270833333333334\n",
            "Epoch: 46 Loss: 0.5004082918167114 Avg Accuracy: 0.9114583333333334\n",
            "Epoch: 47 Loss: 0.45011934638023376 Avg Accuracy: 0.9427083333333334\n",
            "Epoch: 48 Loss: 0.413874089717865 Avg Accuracy: 0.9166666666666666\n",
            "Epoch: 49 Loss: 0.006859415210783482 Avg Accuracy: 0.9375\n",
            "Epoch: 50 Loss: 0.007821956649422646 Avg Accuracy: 0.9322916666666666\n",
            "Epoch: 51 Loss: 0.823207676410675 Avg Accuracy: 0.90625\n",
            "Epoch: 52 Loss: 0.9578632116317749 Avg Accuracy: 0.9010416666666666\n",
            "Epoch: 53 Loss: 0.2719060182571411 Avg Accuracy: 0.9427083333333334\n",
            "Epoch: 54 Loss: 0.2852107882499695 Avg Accuracy: 0.9270833333333334\n",
            "Epoch: 55 Loss: 0.010251961648464203 Avg Accuracy: 0.953125\n",
            "Epoch: 56 Loss: 0.3603128492832184 Avg Accuracy: 0.9114583333333334\n",
            "Epoch: 57 Loss: 0.013652501627802849 Avg Accuracy: 0.9583333333333334\n",
            "Epoch: 58 Loss: 0.010721624828875065 Avg Accuracy: 0.96875\n",
            "Epoch: 59 Loss: 0.0879293754696846 Avg Accuracy: 0.9479166666666666\n",
            "Epoch: 60 Loss: 0.0039029282052069902 Avg Accuracy: 0.9635416666666666\n",
            "Total Average Accuracy 0.8459201388888888\n"
          ]
        }
      ],
      "source": [
        "#1D CNN Test\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(CNN, self).__init__()\n",
        "      self.conv1 = nn.Conv1d(1, 64, 1)\n",
        "      self.pool1 = nn.MaxPool1d(1,1)\n",
        "      self.conv2 = nn.Conv1d(64, 80, 1)\n",
        "      self.pool2 = nn.MaxPool1d(1,1)\n",
        "      self.act1 = nn.ReLU()\n",
        "      self.act2 = nn.LeakyReLU()\n",
        "      #FCL\n",
        "      self.fl1 = nn.Linear(1040, 512)\n",
        "      self.fl2 = nn.Linear(512, 220)\n",
        "      self.fl3 = nn.Linear(220, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = x.view(x.size(0), 1, 13) #(batch_size, num_channels, num_data_per_channel)\n",
        "      x = self.conv1(x)\n",
        "      x = self.act1(x)\n",
        "      x = self.pool1(x)\n",
        "      x = self.conv2(x)\n",
        "      x = self.act2(x)\n",
        "      x = self.pool2(x)\n",
        "      x = x.reshape(x.shape[0], -1) #Flatten\n",
        "      x = self.fl1(x)\n",
        "      x = self.act1(x)\n",
        "      x = self.fl2(x)\n",
        "      x = self.act2(x)\n",
        "      x = self.fl3(x)\n",
        "      return x #CEL so no softmax\n",
        "\n",
        "class WDat(Dataset):\n",
        "  def __init__(self):\n",
        "    self.xy = np.loadtxt(\"/content/wine.csv\",delimiter=\",\",dtype=np.float32,skiprows=1)\n",
        "    self.x = self.xy[:,1:]\n",
        "    self.y = self.xy[:,0]\n",
        "    self.x = torch.from_numpy(self.x)\n",
        "    self.y = torch.from_numpy(self.y).long()-1\n",
        "    self.nsam = len(self.x)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.nsam\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.x[idx], self.y[idx]\n",
        "\n",
        "mydata = WDat()\n",
        "myloader = DataLoader(mydata, batch_size=16, shuffle=True)\n",
        "num_epochs = 60\n",
        "net = CNN()\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adamax(net.parameters(), lr=0.001)\n",
        "\n",
        "avg_acc,num_acc = 0,0\n",
        "for e in range(num_epochs):\n",
        "  avg_acc_e,num_acc_e = 0,0\n",
        "  for (xin, yin) in myloader:\n",
        "    y_pred = net(xin)\n",
        "    _,cls = torch.max(y_pred, 1)\n",
        "    acc = (cls == yin).sum().item()/len(yin)\n",
        "    avg_acc += acc\n",
        "    avg_acc_e += acc\n",
        "    num_acc_e += 1\n",
        "    num_acc += 1\n",
        "    l = loss(y_pred, yin)\n",
        "    optimizer.zero_grad()\n",
        "    l.backward()\n",
        "    optimizer.step()\n",
        "  print(f\"Epoch: {e+1} Loss: {l.item()} Avg Accuracy: {avg_acc_e/num_acc_e}\");\n",
        "print(f\"Total Average Accuracy {avg_acc/num_acc}\")"
      ]
    }
  ]
}